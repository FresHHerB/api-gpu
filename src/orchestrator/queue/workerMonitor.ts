// ============================================
// WorkerMonitor
// Polling em background de jobs submetidos ao RunPod
// ============================================

import { Job, JobOperation } from '../../shared/types';
import { JobStorage } from './jobStorage';
import { RunPodService } from '../services/runpodService';
import { QueueManager } from './queueManager';
import { WebhookService } from './webhookService';
import { logger } from '../../shared/utils/logger';

export class WorkerMonitor {
  private storage: JobStorage;
  private runpodService: RunPodService;
  private queueManager: QueueManager;
  private webhookService: WebhookService;

  private pollingInterval: number; // Intervalo de polling em ms
  private timeoutCheckInterval: number; // Intervalo de checagem de timeout em ms
  private validationInterval: number; // Intervalo de valida√ß√£o de workers em ms
  private isRunning: boolean = false;
  private pollingTimer?: NodeJS.Timeout;
  private timeoutTimer?: NodeJS.Timeout;
  private validationTimer?: NodeJS.Timeout;

  constructor(
    storage: JobStorage,
    runpodService: RunPodService,
    queueManager: QueueManager,
    webhookService: WebhookService,
    pollingInterval: number = 5000, // 5s
    timeoutCheckInterval: number = 60000, // 60s
    validationInterval: number = 300000 // 5min
  ) {
    this.storage = storage;
    this.runpodService = runpodService;
    this.queueManager = queueManager;
    this.webhookService = webhookService;
    this.pollingInterval = pollingInterval;
    this.timeoutCheckInterval = timeoutCheckInterval;
    this.validationInterval = validationInterval;

    logger.info('üëÅÔ∏è WorkerMonitor initialized', {
      pollingInterval: `${pollingInterval}ms`,
      timeoutCheckInterval: `${timeoutCheckInterval}ms`,
      validationInterval: `${validationInterval}ms`
    });
  }

  /**
   * Inicia polling em background
   */
  start(): void {
    if (this.isRunning) {
      logger.warn('‚ö†Ô∏è WorkerMonitor already running');
      return;
    }

    this.isRunning = true;
    logger.info('üöÄ WorkerMonitor started');

    // Loop 1: Polling de jobs ativos
    this.scheduleNextPoll();

    // Loop 2: Verifica√ß√£o de timeouts
    this.scheduleTimeoutCheck();

    // Loop 3: Valida√ß√£o peri√≥dica de worker count
    this.scheduleValidation();
  }

  /**
   * Para polling
   */
  stop(): void {
    this.isRunning = false;

    if (this.pollingTimer) {
      clearTimeout(this.pollingTimer);
      this.pollingTimer = undefined;
    }

    if (this.timeoutTimer) {
      clearTimeout(this.timeoutTimer);
      this.timeoutTimer = undefined;
    }

    if (this.validationTimer) {
      clearTimeout(this.validationTimer);
      this.validationTimer = undefined;
    }

    logger.info('üõë WorkerMonitor stopped');
  }

  /**
   * Agenda pr√≥ximo poll
   */
  private scheduleNextPoll(): void {
    if (!this.isRunning) return;

    this.pollingTimer = setTimeout(async () => {
      await this.pollActiveJobs();
      this.scheduleNextPoll();
    }, this.pollingInterval);
  }

  /**
   * Agenda pr√≥xima checagem de timeout
   */
  private scheduleTimeoutCheck(): void {
    if (!this.isRunning) return;

    this.timeoutTimer = setTimeout(async () => {
      await this.checkTimeouts();
      this.scheduleTimeoutCheck();
    }, this.timeoutCheckInterval);
  }

  /**
   * Agenda pr√≥xima valida√ß√£o de worker count
   */
  private scheduleValidation(): void {
    if (!this.isRunning) return;

    this.validationTimer = setTimeout(async () => {
      await this.validateWorkerCount();
      this.scheduleValidation();
    }, this.validationInterval);
  }

  /**
   * Verifica status de todos os jobs ativos (SUBMITTED, PROCESSING)
   * IMPORTANTE: Apenas jobs GPU/RunPod s√£o monitorados aqui
   * Jobs VPS s√£o gerenciados pelo LocalWorkerService
   */
  private async pollActiveJobs(): Promise<void> {
    try {
      const activeJobs = await this.storage.getActiveJobs();

      if (activeJobs.length === 0) {
        return;
      }

      // Filtrar apenas jobs GPU (RunPod) - pular VPS jobs
      const gpuJobs = activeJobs.filter(job => !this.isVPSJob(job.operation));

      if (gpuJobs.length === 0) {
        return;
      }

      logger.debug(`üîç Polling ${gpuJobs.length} GPU jobs (${activeJobs.length - gpuJobs.length} VPS jobs skipped)`);

      // Poll apenas GPU jobs em paralelo
      await Promise.all(gpuJobs.map(job => this.pollJob(job)));

    } catch (error) {
      logger.error('‚ùå Error polling active jobs', {
        error: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  }

  /**
   * Verifica status de um job espec√≠fico
   */
  private async pollJob(job: Job): Promise<void> {
    if (!job.runpodJobIds || job.runpodJobIds.length === 0) {
      logger.warn('‚ö†Ô∏è Job has no runpodJobIds', { jobId: job.jobId });
      return;
    }

    try {
      // Poll status de todos os runpodJobIds
      const statuses = await Promise.all(
        job.runpodJobIds.map(id => this.runpodService.getJobStatus(id))
      );

      // Atualizar status se mudou para PROCESSING
      const anyProcessing = statuses.some(s => s.status === 'IN_PROGRESS');
      if (anyProcessing && job.status === 'SUBMITTED') {
        const now = new Date();
        await this.storage.updateJob(job.jobId, {
          status: 'PROCESSING',
          processingStartedAt: now  // CRITICAL: Marca in√≠cio da execu√ß√£o para timeout correto
        });
        logger.info('üîÑ Job is now PROCESSING', {
          jobId: job.jobId,
          processingStartedAt: now.toISOString()
        });
      }

      // Verificar se todos completaram
      const allCompleted = statuses.every(s => s.status === 'COMPLETED');
      if (allCompleted) {
        await this.handleJobCompleted(job, statuses);
        return;
      }

      // Verificar se algum falhou
      const anyFailed = statuses.some(
        s => s.status === 'FAILED' || s.status === 'CANCELLED' || s.status === 'TIMED_OUT'
      );
      if (anyFailed) {
        await this.handleJobFailed(job, statuses);
        return;
      }

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';

      logger.error(`‚ùå Error polling job ${job.jobId}`, {
        error: errorMessage
      });

      // Detectar jobs √≥rf√£os (n√£o existem mais no RunPod)
      // Isso acontece quando o endpoint √© recriado e jobs antigos ficam no Redis
      if (error instanceof Error && (
        error.message.includes('404') ||
        error.message.includes('not found') ||
        error.message.includes('does not exist') ||
        error.message.includes('request does not exist')
      )) {
        logger.warn(`üóëÔ∏è Orphaned job detected, marking as FAILED`, {
          jobId: job.jobId,
          reason: 'Job no longer exists in RunPod (likely from old endpoint)'
        });
        await this.handleJobFailed(job, [], `Orphaned job: ${errorMessage}`);
      }
    }
  }

  /**
   * Processa job completado
   */
  private async handleJobCompleted(job: Job, statuses: any[]): Promise<void> {
    logger.info('‚úÖ Job COMPLETED', { jobId: job.jobId });

    // Agregar resultados
    const result = this.aggregateResults(job.operation, statuses);

    // Calcular execution time
    const startTime = job.submittedAt || job.createdAt;
    const endTime = new Date();
    const durationMs = endTime.getTime() - startTime.getTime();

    const execution = {
      startTime: startTime.toISOString(),
      endTime: endTime.toISOString(),
      durationMs,
      durationSeconds: parseFloat((durationMs / 1000).toFixed(2))
    };

    // CRITICAL: Ordem correta para prevenir leaks em caso de crash
    // 1. Liberar workers PRIMEIRO (incrementa semaphore)
    logger.info('üîì Releasing workers before updating job', {
      jobId: job.jobId,
      workersToRelease: job.workersReserved
    });
    await this.queueManager.releaseWorker(job.workersReserved);

    // 2. Zerar workersReserved DEPOIS (marca job como finalizado)
    // Se crash ocorrer antes deste ponto, recoverWorkers() detectar√°
    // e auto-corrigir√° (valida√ß√£o de count em recoverWorkers())
    await this.storage.updateJob(job.jobId, {
      status: 'COMPLETED',
      result: { ...result, execution },
      completedAt: endTime,
      workersReserved: 0 // CRITICAL: Zero out workers to prevent leaks
    });

    logger.info('‚úÖ Job finalized and workers released', {
      jobId: job.jobId,
      workersReleased: job.workersReserved
    });

    // 3. Enviar webhook (n√£o afeta workers)
    await this.webhookService.sendWebhook(job.jobId, job.webhookUrl, {
      jobId: job.jobId,
      idRoteiro: job.idRoteiro,
      pathRaiz: job.pathRaiz,
      status: 'COMPLETED',
      operation: job.operation,
      processor: 'GPU', // Indicate GPU (RunPod) processing
      result,
      execution
    } as any);
  }

  /**
   * Processa job que falhou
   */
  private async handleJobFailed(job: Job, statuses: any[], customError?: string): Promise<void> {
    const errorMessage =
      customError ||
      statuses.find(s => s.error)?.error ||
      'Job failed in RunPod';

    logger.error('‚ùå Job FAILED', { jobId: job.jobId, error: errorMessage });

    // Calcular execution time
    const startTime = job.submittedAt || job.createdAt;
    const endTime = new Date();
    const durationMs = endTime.getTime() - startTime.getTime();

    const execution = {
      startTime: startTime.toISOString(),
      endTime: endTime.toISOString(),
      durationMs,
      durationSeconds: parseFloat((durationMs / 1000).toFixed(2)),
      worker: 'RunPod',
      codec: 'h264_nvenc'
    };

    // CRITICAL: Ordem correta para prevenir leaks em caso de crash
    // 1. Liberar workers PRIMEIRO (incrementa semaphore)
    logger.info('üîì Releasing workers before marking job as failed', {
      jobId: job.jobId,
      workersToRelease: job.workersReserved
    });
    await this.queueManager.releaseWorker(job.workersReserved);

    // 2. Zerar workersReserved DEPOIS (marca job como finalizado)
    await this.storage.updateJob(job.jobId, {
      status: 'FAILED',
      error: errorMessage,
      completedAt: endTime,
      workersReserved: 0 // CRITICAL: Zero out workers to prevent leaks
    });

    logger.info('‚úÖ Failed job finalized and workers released', {
      jobId: job.jobId,
      workersReleased: job.workersReserved
    });

    // 3. Enviar webhook com erro (n√£o afeta workers)
    await this.webhookService.sendWebhook(job.jobId, job.webhookUrl, {
      jobId: job.jobId,
      idRoteiro: job.idRoteiro,
      status: 'FAILED',
      operation: job.operation,
      processor: 'GPU',
      error: {
        code: 'PROCESSING_ERROR',
        message: errorMessage
      },
      execution
    } as any);
  }

  /**
   * Agregar resultados de m√∫ltiplos sub-jobs
   */
  private aggregateResults(operation: JobOperation, statuses: any[]): any {
    if (operation === 'img2vid' && statuses.length > 1) {
      // Multi-worker img2vid: agregar todos os v√≠deos
      const allVideos: any[] = [];
      for (const status of statuses) {
        if (status.output?.videos) {
          allVideos.push(...status.output.videos);
        }
      }

      // Ordenar por filename (video_1.mp4, video_2.mp4, etc)
      allVideos.sort((a, b) => {
        const aNum = parseInt(a.filename.match(/video_(\d+)\.mp4/)?.[1] || '0');
        const bNum = parseInt(b.filename.match(/video_(\d+)\.mp4/)?.[1] || '0');
        return aNum - bNum;
      });

      return {
        code: 200,
        message: `${allVideos.length} videos processed successfully`,
        videos: allVideos
      };
    }

    // Single job: retornar output direto
    return statuses[0]?.output || {};
  }

  /**
   * Verificar timeouts de jobs GPU/RunPod
   * IMPORTANTE: Apenas jobs GPU s√£o verificados
   * Jobs VPS t√™m seu pr√≥prio timeout no LocalWorkerService
   */
  private async checkTimeouts(): Promise<void> {
    try {
      const activeJobs = await this.storage.getActiveJobs();
      const now = Date.now();

      for (const job of activeJobs) {
        // Pular jobs VPS - gerenciados pelo LocalWorkerService
        if (this.isVPSJob(job.operation)) {
          continue;
        }

        // CRITICAL: Usar processingStartedAt se dispon√≠vel (timeout s√≥ durante execu√ß√£o)
        // Se job ainda n√£o come√ßou a executar, usar submittedAt como fallback
        const startTime = job.processingStartedAt || job.submittedAt || job.createdAt;
        const elapsed = now - startTime.getTime();
        const timeout = this.getTimeoutForOperation(job.operation);

        // Se job ainda n√£o come√ßou a executar (sem processingStartedAt), usar timeout de fila
        const isExecuting = !!job.processingStartedAt;
        const effectiveTimeout = isExecuting ? timeout : timeout + (60 * 60 * 1000); // +60min se em fila

        if (elapsed > effectiveTimeout) {
          logger.error('‚è∞ GPU Job TIMEOUT', {
            jobId: job.jobId,
            operation: job.operation,
            elapsedMs: elapsed,
            timeoutMs: effectiveTimeout,
            isExecuting,
            startedFrom: isExecuting ? 'processingStartedAt' : 'submittedAt',
            processingStartedAt: job.processingStartedAt?.toISOString(),
            submittedAt: job.submittedAt?.toISOString()
          });

          // Cancelar jobs RunPod
          for (const rpJobId of job.runpodJobIds) {
            try {
              await this.runpodService.cancelJob(rpJobId);
            } catch (error) {
              logger.warn(`Failed to cancel RunPod job ${rpJobId}`, { error });
            }
          }

          // Marcar como FAILED
          await this.handleJobFailed(
            job,
            [],
            `Job timed out after ${(elapsed / 1000 / 60).toFixed(1)} minutes`
          );
        }
      }
    } catch (error) {
      logger.error('‚ùå Error checking timeouts', {
        error: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  }

  /**
   * Retorna timeout adequado para cada opera√ß√£o GPU (tempo de EXECU√á√ÉO apenas)
   * VPS jobs n√£o s√£o monitorados aqui
   *
   * IMPORTANTE: Estes s√£o timeouts de EXECU√á√ÉO pura (desde processingStartedAt)
   * Tempo de fila √© tratado separadamente (+60min autom√°tico)
   */
  private getTimeoutForOperation(operation: JobOperation): number {
    const executionTimeouts: Record<string, number> = {
      // Baseado em an√°lise de logs reais + requisitos de produ√ß√£o:
      img2vid: 45 * 60 * 1000,           // 45 min (80-150 imgs, 2 workers, ~37 min max + margem)
      caption: 10 * 60 * 1000,           // 10 min (opera√ß√£o r√°pida)
      addaudio: 10 * 60 * 1000,          // 10 min
      caption_segments: 10 * 60 * 1000,  // 10 min
      caption_highlight: 10 * 60 * 1000, // 10 min (m√©dia: 2-3 min)
      concatenate: 20 * 60 * 1000,       // 20 min (m√©dia: 7-9 min, pode ter muitos v√≠deos)
      concat_video_audio: 15 * 60 * 1000,// 15 min (m√©dia: 7-9 min, otimizado com -c copy)
      trilhasonora: 15 * 60 * 1000       // 15 min
    };

    return executionTimeouts[operation] || 30 * 60 * 1000; // Default: 30 min
  }

  /**
   * Valida e auto-corrige worker count periodicamente
   * CRITICAL: Previne worker leaks permanentes
   */
  private async validateWorkerCount(): Promise<void> {
    try {
      logger.info('üîç Starting periodic worker count validation');

      // Tentar recuperar workers leaked
      const recovered = await this.storage.recoverWorkers();

      if (recovered > 0) {
        logger.warn('‚ö†Ô∏è Periodic validation recovered leaked workers', {
          recovered,
          timestamp: new Date().toISOString()
        });
      } else {
        logger.debug('‚úÖ Worker count validation passed - no leaks detected');
      }

    } catch (error) {
      logger.error('‚ùå Error during periodic worker validation', {
        error: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  }

  /**
   * Verifica se job √© VPS (processado localmente)
   */
  private isVPSJob(operation: string): boolean {
    return operation.includes('_vps');
  }
}
